{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd ~/Desktop/programming/Python/twitter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/hollywh/Desktop/programming/Python/twitter\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "full_term_list = {'hiltonhotels':'hilton',\n",
      "                  'hiltonhhonors':'hilton',\n",
      "                  'hiltonworldwide':'hilton',\n",
      "                  'hilton':'hilton',\n",
      "                  'marriott':'marriott',\n",
      "                  'marriottintl':'marriott',\n",
      "                  'renhotels':'marriott',\n",
      "                  'sheratonhotels':'starwood',\n",
      "                  'spg':'starwood',\n",
      "                  'westin':'starwood',\n",
      "                  'whotels':'starwood',\n",
      "                  'starwoodbuzz':'starwood',\n",
      "                  'ihgrewardsclub':'ihg',\n",
      "                  'holidayinn':'ihg',\n",
      "                  'hotelindigo':'ihg',\n",
      "                  'crowneplaza':'ihg',\n",
      "                  'hyatttweets':'hyatt',\n",
      "                  '#travelbrilliantly':'marriott',\n",
      "                  '#beaweekender':'hilton',\n",
      "                  '#spglife':'starwood',\n",
      "                  '#rdiscover':'marriott',\n",
      "                  '#discoverihg':'ihg',\n",
      "                  '#gotmysweaton':'other',\n",
      "                  '#ineedthatbreak':'other' }\n",
      "\n",
      "term_string = \", \".join(full_term_list.keys())   # used in tweet capture file\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Following code extracts a few relevant data fields out of the Twitter Streaming API\n",
      "# Create as individual lists then lump into a dict and create as a dataframe\n",
      "\n",
      "import pandas\n",
      "import re\n",
      "import string\n",
      "#import nltk\n",
      "import time\n",
      "\n",
      "filename = \"output_follow_Apr20_to_May11.txt\"\n",
      "\n",
      "fp = open(filename)\n",
      "count = 0\n",
      "tweetid = []\n",
      "users = []\n",
      "created = []\n",
      "text = []\n",
      "processed_text =[]\n",
      "sentiment = []\n",
      "hashtags = []\n",
      "list_of_term_list = []\n",
      "brand = []\n",
      "\n",
      "is_a_retweet = []\n",
      "retweets = []\n",
      "\n",
      "text_time = 0\n",
      "sent_time = 0\n",
      "brand_time = 0\n",
      "full_time = 0\n",
      "\n",
      "error_lines = []\n",
      "\n",
      "# SET UP PROCESSING VARS -------------------------\n",
      "punct_exclude = set(string.punctuation)\n",
      "\n",
      "# START PROCESSING HERE ------------------------------\n",
      "for ii in range(418000):     \n",
      "  line = fp.readline()    # each tweet is a line\n",
      "  try:\n",
      "      line = eval(line)     # and now each line is a dict\n",
      "      count += 1\n",
      "      if line['lang'] == 'en':   # select only english labeled texts\n",
      "            start_full = time.time()\n",
      "            \n",
      "            # tweetid - take it as is\n",
      "            tweetid.append(line['id'])    \n",
      "            \n",
      "            # users - lower case\n",
      "            users.append(line['user']['screen_name'].lower())   \n",
      "            \n",
      "            # created - can convert to datetime in UTC but user time zone not always available for local time\n",
      "            created.append(line['created_at'])\n",
      "            \n",
      "            # keep raw text, except replace commas with spaces for csv output\n",
      "            txt = re.sub('\\n',' ',line['text'])    # replace newlines with spaces\n",
      "            text.append(re.sub(',',' ', txt))    # replace commas with spaces for csv output\n",
      "            \n",
      "            \n",
      "            start = time.time()\n",
      "            # also process text - lowercase, remove punct - could also stem or remove stop words - not needed with pos/neg dicts using  \n",
      "            # or do it when I have a list?     \n",
      "            #s = re.sub(',',' ', line['text']).lower()\n",
      "            s = line['text'].lower()\n",
      "            s = ''.join(ch for ch in s if ch not in punct_exclude)   # stripping punctuation\n",
      "            s = re.sub('\\n',' ',s)      # also need to strip new lines (was not an issue with text?)\n",
      "            processed_text.append(s)\n",
      "            end = time.time()\n",
      "            text_time += end-start\n",
      "            \n",
      "                \n",
      "                                \n",
      "            # May be multiple hashtags in the tweet - capture all in a space separated string\n",
      "            tag_list = ''\n",
      "            for tag in line['entities']['hashtags']:\n",
      "                tag_list += tag['text'].lower() + \" \"   \n",
      "            hashtags.append(tag_list) \n",
      "            \n",
      "            start = time.time()\n",
      "            # Similarly may be multiple terms - search text and user for items in term_list    \n",
      "            search_term_list = \"\"\n",
      "            brands_list = []\n",
      "            for term in full_term_list.keys():\n",
      "                if line['text'].lower().find(term) >=0 or line['user']['screen_name'].lower().find(term) >= 0:\n",
      "                    search_term_list += term + \" \"\n",
      "                    brands_list.append(full_term_list[term])\n",
      "            list_of_term_list.append(search_term_list)\n",
      "            \n",
      "            # then use set of brands associated with search terms to identify brand\n",
      "            if len(set(brands_list))==1:\n",
      "                brand.append(brands_list[0])\n",
      "            elif len(brands_list)==0:\n",
      "                brand.append('none')\n",
      "            else:\n",
      "                brand.append('mixed')         \n",
      "            end = time.time()\n",
      "            brand_time += end-start\n",
      "            \n",
      "            end_full = time.time()\n",
      "            full_time += end_full-start_full\n",
      "            \n",
      "            if 'retweeted_status' in line.keys():\n",
      "                is_a_retweet.append(line['retweeted_status']['id'])\n",
      "            else:\n",
      "                is_a_retweet.append('')\n",
      "                \n",
      "                          \n",
      "  except:\n",
      "        error_lines.append(ii)\n",
      "\n",
      "# count up the retweets in the batch\n",
      "for tid in tweetid:\n",
      "    total = is_a_retweet.count(tid)\n",
      "    retweets.append(total)\n",
      "\n",
      "print(sum(retweets))\n",
      "\n",
      "# now make the dataframe by creating a dict and then using pandas.DataFrame to convert\n",
      "#data = {'id':tweetid, 'user':users, 'created':created, 'text':text, 'processed_text':processed_text, 'sentiment':sentiment, 'hashtags':hashtags, 'search_terms':list_of_term_list, 'brand':brand, 'retweets':retweets, 'retweet_status':is_a_retweet} \n",
      "data = {'id':tweetid, 'user':users, 'created':created, 'text':text, 'processed_text':processed_text, 'hashtags':hashtags, 'search_terms':list_of_term_list, 'brand':brand, 'retweets':retweets, 'retweet_status':is_a_retweet} \n",
      "\n",
      "tweet_df = pandas.DataFrame(data)  \n",
      "\n",
      "tweet_df.to_csv('threeweek_nosent.csv', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "50323\n"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Scrub out paris and perez hilton and rewrite to new csv\n",
      "\n",
      "print len(tweet_df)\n",
      "drop_conditions = tweet_df['processed_text'].str.contains('paris hilton')\n",
      "tweet_df = tweet_df.drop(tweet_df[drop_conditions].index.values)\n",
      "print len(tweet_df)\n",
      "\n",
      "drop_conditions = tweet_df['processed_text'].str.contains('perez hilton')\n",
      "tweet_df = tweet_df.drop(tweet_df[drop_conditions].index.values)\n",
      "print len(tweet_df)\n",
      "\n",
      "tweet_df.to_csv('threeweek_nosent_noparis.csv', encoding='utf-8')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "245414\n",
        "195220"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "189137"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# NEW PYTHON SCRIPT - open the csv with the dataframe and further process\n",
      "\n",
      "from collections import defaultdict\n",
      "import codecs\n",
      "\n",
      "# okay, for convenience will assume that tweet_df still exists - post paris and perez\n",
      "list(tweet_df.columns.values)\n",
      "\n",
      "brands = list(set(tweet_df['brand']))\n",
      "\n",
      "hashoutfile = codecs.open('hashout.csv','w','utf-8-sig')\n",
      "wordoutfile = codecs.open('wordout10.csv','w','utf-8-sig')\n",
      "\n",
      "for brand in brands:\n",
      "    brand_df = tweet_df[tweet_df['brand']==brand]\n",
      "    \n",
      "    hash_dict = defaultdict(int)\n",
      "    hash_list = list(brand_df['hashtags'])\n",
      "    hash_string = ' '.join(hash_list)\n",
      "    all_hash_list= hash_string.split(' ')\n",
      "    for word in all_hash_list:\n",
      "        if len(word)>0:\n",
      "            hash_dict[word] += 1\n",
      "    for key in hash_dict:\n",
      "        hashoutfile.write(brand + ', ' + key + ', ' + str(hash_dict[key]) + '\\n')\n",
      "        \n",
      "    word_dict = defaultdict(int)\n",
      "    word_list = list(brand_df['processed_text'])\n",
      "    word_string = ' '.join(word_list)\n",
      "    word_string = re.sub('\\n',' ',word_string)\n",
      "    all_word_list = word_string.split(' ')\n",
      "    for word in all_word_list:\n",
      "        if len(word)>0:\n",
      "            word_dict[word] += 1\n",
      "    for key in word_dict:\n",
      "        if word_dict[key] > 10:\n",
      "            wordoutfile.write(brand + ', ' + key + ', ' + str(word_dict[key]) + '\\n')\n",
      "                   \n",
      "hashoutfile.close()\n",
      "wordoutfile.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 263
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ONE MORE SCRIPT - compute sentiment for hilton and marriott only\n",
      "\n",
      "poswords = []\n",
      "for line in open(\"positive-words.txt\"):\n",
      "    li=line.strip()\n",
      "    if not li.startswith(\";\"):\n",
      "        poswords.append(li)\n",
      "poswords.pop(0)    # remove first blank line\n",
      "\n",
      "\n",
      "negwords = []\n",
      "for line in open(\"negative-words.txt\"):\n",
      "    li=line.strip()\n",
      "    if not li.startswith(\";\"):\n",
      "        negwords.append(li)\n",
      "negwords.pop(0)    # remove first blank line\n",
      "\n",
      "sent_df = tweet_df[(tweet_df['brand'] == 'hilton') | (tweet_df['brand'] == 'marriott')]\n",
      "sentfile = open('sentout.csv','w')\n",
      "\n",
      "start = time.time()\n",
      "\n",
      "for index, row in sent_df.iterrows():\n",
      "    #if index > 100:\n",
      "    #    break\n",
      "    s = row['processed_text']\n",
      "    \n",
      "    # now compute sentiment\n",
      "    sent = 0\n",
      "    for word in s.split(' '):\n",
      "        if word in poswords:\n",
      "            sent += 1\n",
      "        elif word in negwords:\n",
      "            sent -= 1\n",
      "    sentfile.write(str(row['id']) + ', ' + str(sent) + '\\n')\n",
      "    \n",
      "sentfile.close()    \n",
      "end = time.time()\n",
      "sent_time += end-start\n",
      "sent_time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 264,
       "text": [
        "3443.2476799488068"
       ]
      }
     ],
     "prompt_number": 264
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TESTING - logic to parse out times - but challenge with user times!\n",
      "\n",
      "#import datetime   # don't use this! strptime not friendly with time zones\n",
      "#datetime.datetime.strptime(created,'%a %b %d %H:%M:%S %z %Y')\n",
      "\n",
      "from dateutil import parser\n",
      "parser.parse(created)\n",
      "\n",
      "# okay, so creates a date time, but if user does not have a timezone - how to convert!\n",
      "print(line['user']['time_zone'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 48,
       "text": [
        "datetime.datetime(2014, 4, 20, 19, 57, 10, tzinfo=tzutc())"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TESTING - lowercase, stem, stopwords, remove punctuation, remove numbers\n",
      "# faster to do each or on the whole list?\n",
      "\n",
      "text = text.lower()\n",
      "\n",
      "import string\n",
      "\n",
      "# removes just trailing and leading\n",
      "text.strip(string.punctuation)\n",
      "\n",
      "# removes all, even within words\n",
      "import string\n",
      "exclude = set(string.punctuation)\n",
      "s = ''.join(ch for ch in text if ch not in exclude)\n",
      "s"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 67,
       "text": [
        "u'im at the westin golf resort amp spa playa conchal cabo velas guanacaste httptcormnlrxldft'"
       ]
      }
     ],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TESTING - sentiment\n",
      "\n",
      "print(text)\n",
      "sent = 0\n",
      "for word in text.split(' '):\n",
      "    if word in poswords:\n",
      "        sent += 1\n",
      "    elif word in negwords:\n",
      "        sent -= 1\n",
      "        \n",
      "sent"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#mraz #europe #concert #hearthemusicseetheworld #spglife #spgmoments #jasonmraz http://t.co/utdlw7cxba\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 95,
       "text": [
        "0"
       ]
      }
     ],
     "prompt_number": 95
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print avg times for various code segments - sentiments is crazy expensive!\n",
      "\n",
      "nrows = len(tweetid)\n",
      "print(text_time/nrows)\n",
      "print(sent_time/nrows)\n",
      "print(brand_time/nrows)\n",
      "print(full_time/nrows)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3.69423717571e-05\n",
        "0\n",
        "0.000105813738371\n",
        "0.000162665640163\n"
       ]
      }
     ],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TESTING - INITIATE FILE OPEN\n",
      "filename = \"output_follow_Apr20_to_May3.txt\"\n",
      "fp = open(filename)\n",
      "line = fp.readline()\n",
      "line = eval(line) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TESTING - GET MORE LINES\n",
      "line = fp.readline()\n",
      "line = eval(line) \n",
      "text = line['text']\n",
      "created = line['created_at']\n",
      "\n",
      "if 'retweeted_status' in line.keys():\n",
      "    print line['retweeted_status']['id']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "457968422610300929\n"
       ]
      }
     ],
     "prompt_number": 134
    }
   ],
   "metadata": {}
  }
 ]
}